# ğŸ›’ Projeto ETL e Dashboard â€“ Online Sales UK

[![Python](https://img.shields.io/badge/Python-3.11-blue?logo=python)](https://www.python.org/)
[![Power BI](https://img.shields.io/badge/PowerBI-Data%20Visualization-yellow?logo=microsoft-power-bi)](https://powerbi.microsoft.com/)
[![SQL Server](https://img.shields.io/badge/SQL%20Server-Database-red?logo=microsoftsqlserver)](https://www.microsoft.com/en-us/sql-server)

## ğŸ“– Contexto
Este projeto utiliza o dataset **Online Retail** disponÃ­vel no Kaggle, mas com fonte direa do [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Online+Retail).  
O dataset contÃ©m transaÃ§Ãµes realizadas entre **01/12/2010 e 09/12/2011** por uma empresa britÃ¢nica de comÃ©rcio eletrÃ´nico, especializada em presentes para todas as ocasiÃµes.

**Fonte:** Dr. Daqing Chen, School of Engineering, London South Bank University, UK.

---

## ğŸ¯ Objetivo
Construir um **pipeline completo de ETL** em Python para:  

1. Extrair o dataset via API do Kaggle  
2. Limpar e tratar os dados  
3. Armazenar em **.parquet**  
4. Carregar os dados no **SQL Server**  
5. Criar dashboards no **Power BI**  

O dashboard permite analisar:  
- Quantidade de produtos vendidos por paÃ­s  
- Produtos mais vendidos  
- Valor total de vendas por paÃ­s  

---
## ğŸ“‚ Estrutura do Projeto
```
Online-Sales-UK---PR_ETL_01/
â”‚
â”œâ”€â”€ data/ # Arquivos de dados (ex: .parquet, .zip, .csv)
â”œâ”€â”€ code/
â”‚ â”œâ”€â”€ config.py # ConexÃ£o com o SQL Server
â”‚ â”œâ”€â”€ import_dataset.py # ExtraÃ§Ã£o do dataset
â”‚ â”œâ”€â”€ load.py # Load de dados no banco
â”‚ â”œâ”€â”€ requirements.txt # DependÃªncias do projeto
â”‚ â”œâ”€â”€ exploration.py # ExploraÃ§Ã£o e tratamento de dados 
â”œâ”€â”€ database/ # Script utilizado no banco de dados
â”œâ”€â”€ PB_PR_ETL_01/ # Arquivos do Power BI
â””â”€â”€ README.md
```
---

## âš™ï¸ ETL â€“ Etapas do Pipeline

### 1ï¸âƒ£ ExtraÃ§Ã£o
- Dataset baixado via API do Kaggle.  
- Arquivo original em CSV importado para Python.

### 2ï¸âƒ£ TransformaÃ§Ã£o
- Limpeza de dados nulos e inconsistÃªncias.  
- ModularizaÃ§Ã£o em arquivos individuais: extraÃ§Ã£o, transformaÃ§Ã£o, load, conexÃ£o.  
- Arquivo final salvo em **.parquet** para performance otimizada.

### 3ï¸âƒ£ Carga (Load)
- Dados carregados no **SQL Server**.  
- ConexÃ£o parametrizada via Python.

### 4ï¸âƒ£ AnÃ¡lise e Dashboard (Power BI)
- ExclusÃ£o de registros de vendas canceladas.  
- Filtros de **data e paÃ­s**.  
- VisualizaÃ§Ãµes:  
  - Quantidade de produtos vendidos por paÃ­s  
  - Produtos mais vendidos  
  - Valor total de vendas por paÃ­s  

---

## ğŸ›  Tecnologias Utilizadas
- **Python:** pandas, pyodbc, sqlalchemy, parquet  
- **SQL Server:** Banco de dados relacional  
- **Power BI:** Dashboards e visualizaÃ§Ãµes  

---


